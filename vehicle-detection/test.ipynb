{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\delai\\anaconda3\\envs\\cctv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "MODEL = YOLO(\"models/yolov8m.pt\", task='detect')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from system.utils import get_computer_name, get_ipv4_address, get_camera_data\n",
    "from system.frame_reader import FrameReader\n",
    "\n",
    "\n",
    "camera_ids, polygons = get_camera_data()\n",
    "frame_reader = FrameReader(camera_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_dict = frame_reader.get_last_frames()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['camera-1', 'camera-3', 'camera-5', 'camera-6'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 14 motorcycles, 1: 384x640 16 persons, 4 chairs, 1 potted plant, 1 tv, 4 laptops, 2: 384x640 3 motorcycles, 1 potted plant, 3: 384x640 1 car, 1 bottle, 1 chair, 50.8ms\n",
      "Speed: 1.2ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "predictions = MODEL.predict(list(frames_dict.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for predict, camera_id in zip(predictions, list(frames_dict.keys())):\n",
    "    results[camera_id] = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[104, 109, 107],\n",
       "        [104, 109, 107],\n",
       "        [104, 110, 105],\n",
       "        ...,\n",
       "        [ 95,  93,  85],\n",
       "        [ 95,  92,  87],\n",
       "        [ 95,  92,  87]],\n",
       "\n",
       "       [[104, 109, 107],\n",
       "        [104, 109, 107],\n",
       "        [104, 110, 105],\n",
       "        ...,\n",
       "        [ 94,  92,  84],\n",
       "        [ 94,  91,  86],\n",
       "        [ 94,  91,  86]],\n",
       "\n",
       "       [[104, 109, 107],\n",
       "        [104, 109, 107],\n",
       "        [104, 110, 105],\n",
       "        ...,\n",
       "        [ 94,  92,  84],\n",
       "        [ 94,  91,  86],\n",
       "        [ 94,  91,  86]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 58,  54,  49],\n",
       "        [ 58,  54,  49],\n",
       "        [ 59,  55,  50],\n",
       "        ...,\n",
       "        [ 46,  43,  38],\n",
       "        [ 47,  44,  39],\n",
       "        [ 47,  44,  39]],\n",
       "\n",
       "       [[ 57,  53,  48],\n",
       "        [ 58,  54,  49],\n",
       "        [ 59,  55,  50],\n",
       "        ...,\n",
       "        [ 45,  45,  39],\n",
       "        [ 45,  45,  39],\n",
       "        [ 45,  45,  39]],\n",
       "\n",
       "       [[ 57,  53,  48],\n",
       "        [ 58,  54,  49],\n",
       "        [ 58,  54,  49],\n",
       "        ...,\n",
       "        [ 44,  44,  38],\n",
       "        [ 44,  44,  38],\n",
       "        [ 44,  44,  38]]], dtype=uint8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\delai\\anaconda3\\envs\\cctv\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\delai\\anaconda3\\envs\\cctv\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\delai\\source\\repos\\Fence\\object-over-fence\\system\\frame_reader.py\", line 43, in update_job\n",
      "    self.update_last_frame()\n",
      "  File \"c:\\Users\\delai\\source\\repos\\Fence\\object-over-fence\\system\\frame_reader.py\", line 24, in update_last_frame\n",
      "    self._last_frame = self.get_frame_from_http_api()\n",
      "  File \"c:\\Users\\delai\\source\\repos\\Fence\\object-over-fence\\system\\frame_reader.py\", line 33, in get_frame_from_http_api\n",
      "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:802: error: (-215:Assertion failed) !buf.empty() in function 'cv::imdecode_'\n",
      "\n",
      "Exception in thread Thread-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\delai\\anaconda3\\envs\\cctv\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\delai\\anaconda3\\envs\\cctv\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\delai\\source\\repos\\Fence\\object-over-fence\\system\\frame_reader.py\", line 43, in update_job\n",
      "    self.update_last_frame()\n",
      "  File \"c:\\Users\\delai\\source\\repos\\Fence\\object-over-fence\\system\\frame_reader.py\", line 24, in update_last_frame\n",
      "    self._last_frame = self.get_frame_from_http_api()\n",
      "  File \"c:\\Users\\delai\\source\\repos\\Fence\\object-over-fence\\system\\frame_reader.py\", line 33, in get_frame_from_http_api\n",
      "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:802: error: (-215:Assertion failed) !buf.empty() in function 'cv::imdecode_'\n",
      "\n",
      "Exception in thread Thread-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\delai\\anaconda3\\envs\\cctv\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\delai\\anaconda3\\envs\\cctv\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\delai\\source\\repos\\Fence\\object-over-fence\\system\\frame_reader.py\", line 43, in update_job\n",
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\delai\\anaconda3\\envs\\cctv\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.update_last_frame()\n",
      "  File \"c:\\Users\\delai\\source\\repos\\Fence\\object-over-fence\\system\\frame_reader.py\", line 24, in update_last_frame\n",
      "    self._last_frame = self.get_frame_from_http_api()\n",
      "  File \"c:\\Users\\delai\\source\\repos\\Fence\\object-over-fence\\system\\frame_reader.py\", line 33, in get_frame_from_http_api\n",
      "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:802: error: (-215:Assertion failed) !buf.empty() in function 'cv::imdecode_'\n",
      "\n",
      "    self.run()\n",
      "  File \"c:\\Users\\delai\\anaconda3\\envs\\cctv\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\delai\\source\\repos\\Fence\\object-over-fence\\system\\frame_reader.py\", line 43, in update_job\n",
      "    self.update_last_frame()\n",
      "  File \"c:\\Users\\delai\\source\\repos\\Fence\\object-over-fence\\system\\frame_reader.py\", line 24, in update_last_frame\n",
      "    self._last_frame = self.get_frame_from_http_api()\n",
      "  File \"c:\\Users\\delai\\source\\repos\\Fence\\object-over-fence\\system\\frame_reader.py\", line 33, in get_frame_from_http_api\n",
      "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
      "cv2.error: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgcodecs\\src\\loadsave.cpp:802: error: (-215:Assertion failed) !buf.empty() in function 'cv::imdecode_'\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "results['camera-3'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'camera-3': ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       " orig_img: array([[[104, 109, 107],\n",
       "         [104, 109, 107],\n",
       "         [104, 110, 105],\n",
       "         ...,\n",
       "         [ 95,  93,  85],\n",
       "         [ 95,  92,  87],\n",
       "         [ 95,  92,  87]],\n",
       " \n",
       "        [[104, 109, 107],\n",
       "         [104, 109, 107],\n",
       "         [104, 110, 105],\n",
       "         ...,\n",
       "         [ 94,  92,  84],\n",
       "         [ 94,  91,  86],\n",
       "         [ 94,  91,  86]],\n",
       " \n",
       "        [[104, 109, 107],\n",
       "         [104, 109, 107],\n",
       "         [104, 110, 105],\n",
       "         ...,\n",
       "         [ 94,  92,  84],\n",
       "         [ 94,  91,  86],\n",
       "         [ 94,  91,  86]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 58,  54,  49],\n",
       "         [ 58,  54,  49],\n",
       "         [ 59,  55,  50],\n",
       "         ...,\n",
       "         [ 46,  43,  38],\n",
       "         [ 47,  44,  39],\n",
       "         [ 47,  44,  39]],\n",
       " \n",
       "        [[ 57,  53,  48],\n",
       "         [ 58,  54,  49],\n",
       "         [ 59,  55,  50],\n",
       "         ...,\n",
       "         [ 45,  45,  39],\n",
       "         [ 45,  45,  39],\n",
       "         [ 45,  45,  39]],\n",
       " \n",
       "        [[ 57,  53,  48],\n",
       "         [ 58,  54,  49],\n",
       "         [ 58,  54,  49],\n",
       "         ...,\n",
       "         [ 44,  44,  38],\n",
       "         [ 44,  44,  38],\n",
       "         [ 44,  44,  38]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'image1.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 1.2101531028747559, 'inference': 12.690246105194092, 'postprocess': 1.9739866256713867}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\delai\\anaconda3\\envs\\cctv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import ctypes\n",
    "import multiprocessing\n",
    "import multiprocessing.sharedctypes\n",
    "import multiprocessing.synchronize\n",
    "import signal\n",
    "from typing import cast\n",
    "from time import perf_counter\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import ultralytics as ul\n",
    "import os\n",
    "def _update(args: tuple, props: dict[int, float], buffer: ctypes.Array[ctypes.c_uint8], ready: multiprocessing.synchronize.Event, cancel: multiprocessing.synchronize.Event):\n",
    "\n",
    "    signal.signal(signal.SIGINT, signal.SIG_IGN)\n",
    "\n",
    "    video_capture = cv2.VideoCapture(*args)\n",
    "    if not video_capture.isOpened():\n",
    "        raise IOError()\n",
    "\n",
    "    _set_props(video_capture, props)\n",
    "\n",
    "    try:\n",
    "        while not cancel.is_set():\n",
    "            ret, mat = cast(\"tuple[bool, cv2.Mat]\", video_capture.read())\n",
    "            if not ret:\n",
    "                continue\n",
    "\n",
    "            ready.clear()\n",
    "            memoryview(buffer).cast('B')[:] = memoryview(mat).cast('B')[:]\n",
    "            ready.set()\n",
    "\n",
    "    finally:\n",
    "        video_capture.release()\n",
    "def _set_props(video_capture: cv2.VideoCapture, props: dict[int, float]):\n",
    "    for key, value in props.items():\n",
    "        try:\n",
    "            video_capture.set(key, value)\n",
    "        except:\n",
    "            pass\n",
    "def _get_props(video_capture: cv2.VideoCapture) -> dict[int, float]:\n",
    "    ids = [cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FRAME_WIDTH]\n",
    "    return cast(\"dict[int, float]\", dict([[prop, video_capture.get(prop)] for prop in ids]))\n",
    "def _get_information(args: tuple, in_props: dict[int, float]) -> tuple[tuple[int, int, int], dict[int, float]]:\n",
    "    \n",
    "    video_capture = cv2.VideoCapture(*args)\n",
    "    if not video_capture.isOpened():\n",
    "        raise IOError()\n",
    "\n",
    "    _set_props(video_capture, in_props)\n",
    "    out_props = _get_props(video_capture)\n",
    "\n",
    "    try:\n",
    "        ret, mat = cast(\"tuple[bool, cv2.Mat]\", video_capture.read())\n",
    "        if not ret:\n",
    "            raise IOError()\n",
    "\n",
    "        return mat.shape, out_props\n",
    "\n",
    "    finally:\n",
    "        video_capture.release()\n",
    "class VideoCaptureWrapper:\n",
    "    def __init__(self, *args) -> None:\n",
    "        self.__args = ()\n",
    "        self.__shape = cast(int, 0), cast(int, 0), cast(int, 0)\n",
    "        self.__props: dict[int, float] = {}\n",
    "\n",
    "        self.__buffer = multiprocessing.sharedctypes.RawArray(\n",
    "            ctypes.c_uint8, 1)\n",
    "        self.__ready = multiprocessing.Event()\n",
    "        self.__cancel = multiprocessing.Event()\n",
    "        self.__enqueue = multiprocessing.Process()\n",
    "\n",
    "        self.__released = cast(bool, True)\n",
    "\n",
    "        if len(args) == 0:\n",
    "            return\n",
    "\n",
    "        self.open(*args)\n",
    "\n",
    "    def open(self, *args):\n",
    "        if not self.__released:\n",
    "            raise RuntimeError()\n",
    "\n",
    "        self.__args = args\n",
    "        self.__shape, self.__props = _get_information(\n",
    "            self.__args, self.__props)\n",
    "\n",
    "        height, width, channels = self.__shape\n",
    "        self.__buffer = multiprocessing.sharedctypes.RawArray(\n",
    "            ctypes.c_uint8, height * width * channels)\n",
    "\n",
    "        self.__ready = multiprocessing.Event()\n",
    "        self.__cancel = multiprocessing.Event()\n",
    "        self.__enqueue = multiprocessing.Process(target=_update, args=(\n",
    "            self.__args, self.__props, self.__buffer, self.__ready, self.__cancel), daemon=True)\n",
    "        self.__enqueue.start()\n",
    "\n",
    "        self.__released = cast(bool, False)\n",
    "\n",
    "    def get(self, propId: int):\n",
    "        if self.__released:\n",
    "            raise RuntimeError()\n",
    "\n",
    "        return self.__props[propId]\n",
    "\n",
    "    def set(self, propId: int, value: float):\n",
    "        if self.__released:\n",
    "            raise RuntimeError()\n",
    "\n",
    "        self.__props[propId] = value\n",
    "        self.release()\n",
    "        self.open(*self.__args)\n",
    "\n",
    "        return cast(bool, True)\n",
    "\n",
    "    def read(self):\n",
    "        if self.__released:\n",
    "            raise RuntimeError()\n",
    "\n",
    "        self.__ready.wait()\n",
    "        return cast(bool, True), np.reshape(self.__buffer, self.__shape).copy()\n",
    "\n",
    "    def isOpened(self):\n",
    "        return not self.__released\n",
    "\n",
    "    def release(self):\n",
    "        if self.__released:\n",
    "            return\n",
    "\n",
    "        self.__cancel.set()\n",
    "        self.__enqueue.join()\n",
    "        self.__released = True\n",
    "\n",
    "    def __del__(self):\n",
    "        try:\n",
    "            self.release()\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "\n",
    "multiprocessing.freeze_support()\n",
    "\n",
    "vid = VideoCaptureWrapper(\"rtsp://admin:vuletech123@192.168.1.126:554/cam/realmonitor?channel=1&subtype=0\") \n",
    "\n",
    "while(True): \n",
    "    \n",
    "    ret, frame = vid.read() \n",
    "    frame = cv2.resize(frame, (1280, 720))\n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('frame', frame) \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "\n",
    "# After the loop release the cap object \n",
    "vid.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "rtsp = \"\"\n",
    "cap = cv2.VideoCapture()\n",
    "while True: \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cctv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
